---
title: "Risk and confidence maps for `r params$species`"
author: 
  - name:  "Amy J.S Davis"
  - name:  "Peter Desmet" 
  - name:  "Damiano Oldoni"
  - name:  "Soria Delva"
date: "`r Sys.Date()`"
output:
  html_notebook:
    toc: yes
    toc_depth: 3
  html_document: 
    toc: no
  pdf_document:
    toc: 
    toc_depth: '3'
params:
  species: Vaccinium corymbosum
  GBIF_taxonkey: '2882849'
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,error = TRUE)
```



```{r load libraries,echo=FALSE,message=FALSE}
options("rgdal_show_exportToProj4_warnings"="none")
library(sdm)
library(rgdal)
library(raster)
library(maps)
library(spocc)
library(sp)
library(rgeos)
library(SDMPlay) #PROBLEM
library(tidyverse)
library(caret)
library(caretEnsemble)
library(gbm)
library(trias)
library(rgbif)
library(RColorBrewer)
library(maptools) #PROBLEM
library(dismo)
library(sf)
library(geoR)
library(pdp)
library(purrr)
library(here)
library(CoordinateCleaner)
library(humboldt) #PROBLEM
library(knitr)
library(kableExtra)
library(PresenceAbsence)
library(rmarkdown)

```
### 1, Download global occurrence data from GBIF
Retrieve the `taxonKey`s we want to use to download occurrences:

```{r retrieve_taxon_data}
# TO DO: specify the scientific name of the species to be modelled
species<- c("Vaccinium corymbosum", "Erigeron karvinskianus DC.", "Houttuynia cordata", "Leycesteria formosa", "Verbena bonariensis")

# Match species names with the GBIF backbone, retrieve taxon keys from GBIF when a match is found
taxon_df <- as.data.frame(species)

mapped_taxa <- purrr::map_dfr(
  taxon_df$species,
  ~ {
    tryCatch(
      {
        data <- rgbif::name_backbone(name = .x)
        if (length(data) == 0) {
          stop("No match with the GBIF backbone found")
        }
        data
      },
      error = function(e) {
        NULL
      }
    )
  }
)

#Make sure that only species info is stored as it is possible that genus information is captured when the species part of the name is not clear
mapped_taxa<-mapped_taxa %>%
  filter(rank =="SPECIES")

#Make sure that all species were mapped to the GBIF backbone, if not an error will appear indicating which species are missing
assertthat::assert_that(nrow(mapped_taxa)==length(species),
                        msg=paste0("The following species could not be found in the GBIF backbone taxonomy: "
                                   ,species[!sapply(species, function(x) any(grepl(x,mapped_taxa$scientificName)))])
)

not_accepted <- mapped_taxa %>%
                dplyr::filter(status !="ACCEPTED")

if (nrow(not_accepted)!=0) {
      warning(paste0("The following species do not have an accepted taxonomic status in the GBIF backbone: "
                     ,species[sapply(species, function(x) any(grepl(x,not_accepted$scientificName)))])
      )
} else {
  paste0("All species are accepted taxa in the GBIF backbone ðŸŽ‰")
}

#Explore mapped_taxa 
mapped_taxa

#Extract taxonkeys of each species
taxon_key<-mapped_taxa$usageKey

#Create taxa_input file, holding information that will be added further down to gbif_downloads.tsv
taxa_input_file<-mapped_taxa[,c(1,2,8)]

#Remove objects 
remove(mapped_taxa, not_accepted, taxon_df)

```

### Basis of record


```{r define_basis_of_record_eu}
#All types of occurrences are downloaded, except `FOSSIL SPECIMEN` and `LIVING SPECIMEN`, which can have misleading location information (e.g. location of captive animal).

basis_of_record <- c(
  "OBSERVATION", 
  "HUMAN_OBSERVATION",
  "MATERIAL_SAMPLE",
  "PRESERVED_SPECIMEN", 
  "UNKNOWN", 
  "MACHINE_OBSERVATION",
  "OCCURRENCE"
)
```

### Specify time period to download occurrence data 
```{r define_year_eu}
year_begin <- 1971
year_end <-2010
```

### Download only georeferenced points

```{r define_hasCoordinate_eu}
hasCoordinate <- TRUE
```

### Trigger download

**Note**: GBIF credentials are required in the next step. 

Trigger download:

```{r trigger_gbif_download_eu}

 gbif_download_key <- occ_download(
   pred_in("taxonKey", taxon_key),
   pred_in("basisOfRecord", basis_of_record),
   pred_gte("year", year_begin),
   pred_lte("year", year_end),
  pred("hasCoordinate", hasCoordinate),
   user = rstudioapi::askForPassword("GBIF username"),
   pwd = rstudioapi::askForPassword("GBIF password"),
   email = rstudioapi::askForPassword("Email address for notification")
 )
```

### Check status of download

```{r check_metadata_eu}

occ_download_wait(gbif_download_key)

```



```{r retrieve_GBIF_download}
occ_download_get(gbif_download_key, path = here("data","raw"), overwrite=TRUE)
```

###Write download to list of downloads and check pending downloads:

```{r update_download_list_eu}
#If the file gbif_downloads.tsv does not exist, create and store an empty file
if(!file.exists(here::here("data", "raw", "gbif_downloads.tsv"))) {
  download_list<-data.frame(
    gbif_download_key= character(),
    input_checklist= character(),
    gbif_download_created=character(),
    gbif_download_status=character(),
    gbif_download_doi=character()
  )
  write_tsv(download_list, here::here("data", "raw", "gbif_downloads.tsv"))
  
  remove(download_list)
}

update_download_list(
  file = here::here("data", "raw", "gbif_downloads.tsv"), 
  download_to_add = gbif_download_key, 
  input_checklist = taxa_input_file
)
```

```{r extract_GBIF_occurrence}
raw.path<- here("data/raw//")
unzip(paste0(raw.path,gbif_download_key,".zip"),exdir=paste0(raw.path,gbif_download_key))

global<-as.data.frame(data.table::fread(paste0(raw.path,gbif_download_key,"/occurrence.txt"),header=TRUE))
```

#split dataframe by taxon key
```{r split_GBIF_occurrence_bySpecies}
sort(unique(global$acceptedScientificName))
split_df<-split(global,global$acceptedScientificName) 
lapply(names(split_df), function(x) {
  species_name<- sub("\\.$", "", x)
  write.csv(split_df[[x]], file = paste0(raw.path, "/",species_name, ".csv"))
})
```

### 2. Create a global SDM 
##### 2. Specify paths for output (defaults to file structure in ReadMe)
```{r defineOutputPaths, echo=FALSE}
rasterOutput<-here("data/processed/geotiffs/")
pdfOutput<-here("data/processed/pdf/")
genOutput<-here("data/processed/general//")
```
####3. Filter global occurrence data 
```{r decimal places,echo=FALSE}
#This function calculates the number of decimal places in any given numeric value 
# eg., 15.21 has 2 decimal places, 15.2569 has 4 decimal places, 15.25690 also has 4, as 0 in the end doesn't count
decimalplaces <- function(x) {
  if (abs(x - round(x)) > .Machine$double.eps^0.5) {
    nchar(strsplit(sub('0+$', '', as.character(x)), ".", fixed = TRUE)[[1]][[2]])
  } else {
    return(0)
  }
}
```

```{r filter global occurrence data}

#remove unverified records
identificationVerificationStatus_to_discard <- c( "unverified",
                                                  "unvalidated",
                                                  "not validated",
                                                  "under validation",
                                                  "not able to validate",
                                                  "control could not be conclusive due to insufficient knowledge",
                                                  "1",
                                                  "uncertain",
                                                  "unconfirmed",
                                                  "Douteux",
                                                  "Invalide",
                                                  "Non r\u00E9alisable",
                                                  "verification needed" ,
                                                  "Probable",
                                                  "unconfirmed - not reviewed",
                                                  "validation requested")

#enter value for max coordinate uncertainty in meters.

global.occ<-global %>%
  dplyr::filter(speciesKey%in%taxon_key) %>%   #using taxonKey filters out accepted synonyms, DO WE WANT THAT?
  dplyr::filter(is.na(coordinateUncertaintyInMeters)| coordinateUncertaintyInMeters<= 1000) %>%
  dplyr::filter(!str_to_lower(identificationVerificationStatus) %in% identificationVerificationStatus_to_discard)

 global.occ$lon_dplaces<-sapply(global.occ$decimalLongitude, function(x) decimalplaces(x))
 global.occ$lat_dplaces<-sapply(global.occ$decimalLatitude, function(x) decimalplaces(x))
 global.occ[global.occ$lon_dplaces < 4& global.occ$lat_dplaces < 4 , ]<-NA
 global.occ<-global.occ[ which(!is.na(global.occ$lon_dplaces)),]
 global.occ<-within(global.occ,rm("lon_dplaces","lat_dplaces"))
global.occ<-global.occ[which( global.occ$year > 1970 & global.occ$year < 2011),]

``` 

#### Convert global occurrences to spatial points needed for modelling

```{r occ to spatialData,echo=FALSE}
global.occ<-global.occ[c("decimalLongitude", "decimalLatitude")]
coordinates(global.occ)<- c("decimalLongitude", "decimalLatitude")
global.occ.LL<-data.frame(global.occ)[c(1:2)] #extract long and lat 

```
#### Flag and remove centroids and invalid georeferenced points
```{r remove invalid_pts_and_centroids,echo=FALSE}
global.occ.LL$species<-rep("Vaccinium corymbosum",nrow(global.occ.LL))  

flags_report<-clean_coordinates(x = global.occ.LL, lon= "decimalLongitude", lat= "decimalLatitude",
                          tests = c("capitals", 
                          "centroids","gbif", "institutions", 
                           "seas", "zeros"))

cleaned<-clean_coordinates(x = global.occ.LL, lon= "decimalLongitude", lat= "decimalLatitude",
                          tests = c("capitals", 
                          "centroids","gbif", "institutions", 
                           "seas", "zeros"),value="clean")
global.occ.LL.cleaned<-subset(cleaned,select= -c(species))
```
#### Create global rasterstack using CHELSA data for model building

```{r importChelsaData,echo=TRUE}
globalclimrasters <- list.files((here("./data/external/climate/trias_CHELSA")),pattern='tif',full.names = T) #import CHELSA data
globalclimpreds <- stack(globalclimrasters)
```

#### Use SDMtab command from the SDMPlay package to remove duplicates per grid cell

```{r remove global duplicates,echo=TRUE}

global.SDMtable<- SDMPlay:::SDMtab(global.occ.LL.cleaned, globalclimpreds, unique.data = TRUE,background.nb= 0) #
numb.global.pseudoabs <-length(global.SDMtable$id) #sets the number of pseudoabsences equal to number of unique presences


global.occ.sp<-global.SDMtable[c("longitude", "latitude")]
coordinates(global.occ.sp)<- c("longitude", "latitude")
global.occ.sp$species<- rep(1,length(global.occ.sp$latitude)) #adds columns indicating species presence needed for modeling
```
### plot distribution of cleaned global occurrences
```{r plot_global_occ,echo=TRUE}
maps::map('world', fill = FALSE, wrap=c(-180,180))
plot(global.occ.sp,pch=21,bg="green",cex=.5,add=TRUE)
```
### Select wwf ecoregions that contain global occurrence points

```{r select ecoregions,cache= TRUE,echo=FALSE}
wwf_eco<-shapefile(here("./data/external/GIS/official/wwf_terr_ecos.shp"))
crs(global.occ.sp)<-CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0")
occ_ecoIntersect <- over(wwf_eco,global.occ.sp) 
wwf_ecoSub1 <- wwf_eco[!is.na(occ_ecoIntersect$species),]
```

### Specify and import bias grids for relevant taxonomic group (e.g vascular plants) 

```{r importBiasgrid}
biasgrid<-raster(here("./data/external/bias_grids/final/trias/plants_1deg_min5.tif"))### specify appropriate bias grid here

```

### Subset bias grid by ecoregions containing occurrence points

```{r subsetBiasgrid}
ext_wwf_ecoSub<-extent(wwf_ecoSub1)
biasgrid_crop<-crop(biasgrid,ext_wwf_ecoSub)
biasgrid_sub<-mask(biasgrid_crop,wwf_ecoSub1)
 plot(biasgrid_sub)
 plot(wwf_ecoSub1,add=TRUE)
 
```

###  Use randomPoints function from dismo package to locate pseduobasences within the bias grid subset 

```{r locatePseudo_absences}
# generates pseudo absences equal to (or close to) the number of presences.
set.seed(728)
global_points<-randomPoints(biasgrid_sub,numb.global.pseudoabs, global.occ.sp, ext=NULL, extf=1.1, excludep=TRUE, prob=FALSE, cellnumbers=FALSE, tryf=70, warn=2, lonlatCorrection=TRUE) 
# will throw a warning if randomPoints generated is less than numb.pseudoabs. If this happens, increase the number of tryf or ignore bias grid and sample from ecoregion only.
```

### OPTIONAL: Sample from ecoregion only
#### run if the bias grid subset of ecoregions results in too small of an area for sampling
```{r locatePseudo_absences_inEcoregions}
#  wwf_grid<-raster(here("./data/external/GIS/wwf_ecoregions_v1.tif"))
#  ecoregions_raster<-mask(wwf_grid,wwf_ecoSub1)
#  set.seed(768)
#  global_points<-randomPoints(ecoregions_raster, numb.pseudoabs, global.occ.sp, ext=NULL, extf=1.1, excludep=TRUE, prob=FALSE, cellnumbers=FALSE, tryf=150, warn=2, lonlatCorrection=TRUE) 
```

### Extract generated pseudo absences and create presence-pseudobasence dataset 

```{r create_presence_absence_dataset}
global_pseudoAbs<-as.data.frame(global_points)
coordinates(global_pseudoAbs)<-c("x","y")
crs(global_pseudoAbs)<-CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0")
global_pseudoAbs$species<-rep(0,length(global_pseudoAbs$x))
global_presabs<- spRbind(global.occ.sp,global_pseudoAbs) # join pseudoabsences with presences (occurrences)

```

### Extract climate data for global scale modelling

```{r extractClimateData,message=FALSE}

global.data <- sdmData(species~.,train=global_presabs, predictors=globalclimpreds)
global.data.df<-as.data.frame(global.data)
```

### Identify highly correlated predictors

```{r identifyCorrelatedPreds,echo=FALSE}
correlationMatrix<-cor(global.data.df[,-c(1)])
highlyCorrelated <- findCorrelation(correlationMatrix, cutoff=0.7,exact=TRUE,names=TRUE)
preds<-as.data.frame(highlyCorrelated)
kable(preds) %>%
kable_styling(bootstrap_options = c("striped"))
```

### Remove highly correlated predictors from dataframe 

```{r removeCorrelatedPreds,echo=FALSE,message=FALSE,warning=FALSE}
global.data.df.subset<-select (global.data.df,-c(highlyCorrelated))
global.data.df.subset<-within(global.data.df.subset,rm("rID"))
global.data.df.subset$species<-as.factor(global.data.df.subset$species) #later steps require non numeric dependent variable
levels(global.data.df.subset$species)<-c("absent","present")
global.data.df.subset$species <- relevel(global.data.df.subset$species, ref = "present") 
```
### Correct global clim preds values from integer format

```{r correctPreds,echo=FALSE}
divide10<-function(x){
  value<-x/10
  return(value)
}


global.data.df.uncor<-cbind("species"=  global.data.df.subset$species,divide10(global.data.df.subset[,-c(1)]))
```



### Use caretList from Caret package to run multiple machine learning models

```{r run_globalModel,cache=TRUE,results= 'hide',message=FALSE,warning=FALSE}

control <- trainControl(method="cv",number=10,savePredictions="final", preProc=c("center","scale"),classProbs=TRUE)
classList1 <- c("glm","gbm","rf","earth")
set.seed(457)
global_train <- caretList(
  species~., data= global.data.df.uncor,
  trControl=control,
    methodList=classList1)
```
```{r print_globalModelAccuracy,warning=FALSE}
GlobalModelResults<-resamples(global_train)
Global.Mod.Accuracy<-summary(GlobalModelResults)# displays accuracy of each model
kable(Global.Mod.Accuracy$statistics$Accuracy,digits=2) %>%
kable_styling(bootstrap_options = c("striped"))
```
```{r print_globalModelKappa,warning=FALSE}
GlobalModelResults<-resamples(global_train)
kable(Global.Mod.Accuracy$statistics$Kappa,digits=2) %>%
kable_styling(bootstrap_options = c("striped"))
```
```{r print_globalModelCorrelation,warning=FALSE}
Global.Mod.Cor<-modelCor(resamples(global_train))# shows correlation among models.Weakly correlated algorithms are persuasive for stacking them in ensemble.
kable(Global.Mod.Cor,digits=2)%>%
kable_styling(bootstrap_options = c("striped"))
```
### Create ensemble model (combine individual models into one) 
```{r run global_ensemble,TRUE}
set.seed(478)
global_stack <- caretEnsemble(
  global_train, 
  trControl=trainControl(method="cv",
                         number=10,
                         savePredictions= "final",classProbs=TRUE ))
print(global_stack)
```

### Function to return threshold where sens=spec from caret results 
```{r run accuracy_funcs}
findThresh<-function(df){
  df[c("rowIndex","obs","present")]
  df<-df %>%
    mutate(observed= ifelse(obs == "present",1,0)) %>%
    select(rowIndex,observed,predicted=present)
  result<-PresenceAbsence::optimal.thresholds(df,opt.methods = 2)
  return(result)
}

#accuracy measures
accuracyStats<-function(df,y){
  df[c("rowIndex","obs","present")]
  df<-df %>%
    mutate(observed= ifelse(obs == "present",1,0)) %>%
    select(rowIndex,observed,predicted=present)
  result<-PresenceAbsence::presence.absence.accuracy(df,threshold = y,st.dev=FALSE)
  return(result)
}
```

### Identify threshold and performance of global ensemble model
```{r evaluate global_ensemble}
global.ens.thresh<-findThresh(global_stack$ens_model$pred)
accuracyStats(global_stack$ens_model$pred,global.ens.thresh$predicted)
```
### Create rasterstack of CHELSA climate data clipped to European modeling extent for prediction

```{r prepareEU_chelsaData,echo=TRUE}
euclimrasters <- list.files((here("./data/external/climate/chelsa_eu_clips")),pattern='tif',full.names = T)
eu_climpreds<-stack(euclimrasters)
eu_climpreds.10<-divide10(eu_climpreds) # correct for integer format of Chelsa preds

```

### Restrict global model prediction to the extent of Europe
```{r predictGlobal, cache=TRUE,echo=FALSE}
 global_model<-raster::predict(eu_climpreds.10,global_stack,type="prob")
```
### Plot global model prediction
```{r plotGlobal,echo=FALSE}
brks <- seq(0, 1, by=0.1) 
  nb <- length(brks)-1 
  pal <- colorRampPalette(rev(brewer.pal(8, 'Spectral')))
  cols<-pal(nb)
  plot(global_model, breaks=brks, col=cols,lab.breaks=brks) 
 plot(global.occ.sp,pch=21,col="white",cex=0.70,add=TRUE)
```
### Export global model prediction
```{r exportGlobal}
writeRaster(global_model, filename=file.path(rasterOutput,paste("GlobalEnsEU_",taxonkey, ".tif",sep="")),format="GTiff",overwrite=TRUE) 
```
### Get variable importance of global model

```{r get_var_importance}
variableImportance_global<-varImp(global_stack)
kable(variableImportance_global,digits=2,caption="Variable Importance") %>%
kable_styling(bootstrap_options = c("striped"))
write.csv(variableImportance_global,file = paste0(genOutput,taxonkey,"_varImp_global_model.csv"))
```

### Create European subset
```{r subset_eu_occurrences,echo=FALSE}
euboundary<-shapefile(here("./data/external/GIS/EUROPE.shp")) 
euboundaryLL<-spTransform(euboundary,"+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0")
occ.eu  <- global.occ.sp[euboundaryLL,]
plot(euboundaryLL)
plot(occ.eu,pch=21,bg="green",cex=.5,add=TRUE)
```

### Create RasterStack of European climate variables from RMI

# stack climate data 
```{r stack all_euclimate_preds}  
rmiclimrasters <- list.files((here("./data/external/climate/rmi_corrected")),pattern='tif',full.names = T) 
rmiclimrasters #shows all available climate data
rmiclimpreds <- stack(rmiclimrasters) #includes all available climate data
```


### Transform eu occurrence dataset with unique presences back to a SpatialPoints dataframe. 

```{r eu_occurences_to_spatialDF}
euocc<-as.data.frame(occ.eu@coords)
coordinates(euocc)<- c("longitude", "latitude")
euocc$occ<- rep(1,length(euocc$latitude))#adds columns indicating species presence needed for modeling
proj4string(euocc)<-CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0")#specify here the existing projection of the data
LLproj<-CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0")

rmiproj<-CRS("+proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000 +ellps=GRS80 +towgs84=0,0,0,-0,-0,-0,0 +units=m +no_defs")
euocc1<-spTransform(euocc,rmiproj)
```

### Clip bias grid to European extent

```{r clip_biasgrid}
studyextent<-euboundary
ecoregions_eu<-crop(biasgrid_sub,studyextent)
biasgrid_eu<-projectRaster(ecoregions_eu,rmiclimpreds)
plot(biasgrid_eu)
plot(studyextent,add=TRUE)
```

### Mask areas of high habitat suitability from global climate model
```{r mask highSuitability}
wgs84_gcs<-CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0")
crs(global_model)<-wgs84_gcs
#m<-global_model >.5 
m<-global_model >= global.ens.thresh$predicted
global_mask<-mask(global_model,m,maskvalue=TRUE)
global_masked_proj<-projectRaster(global_mask,biasgrid_eu)
plot(global_masked_proj)
```

### Combine areas of low predicted habitat suitability with bias grid to exclude low sampled areas and areas of high suitability

```{r create_pseudoSamplingArea}
pseudoSamplingArea<-mask(global_masked_proj,biasgrid_eu)
plot(pseudoSamplingArea)
```

### Randomly locate pseudo absences within "pseudoSamplingArea" 
```{r create_eu_pseudoAbsences}

# set number of pseudoabsences equal to the number of presences
numb.eu.pseudoabs<-nrow(euocc1)

# takes 10 draws of random pseudoabsences, returns as dataframes and names them X1-X10
setlist<-seq(1,10,1)
set.seed(120)
pseudoabs_pts<-lapply(setlist,function(x) as.data.frame(randomPoints(pseudoSamplingArea, numb.eu.pseudoabs , euocc, ext=NULL, extf=1.1, excludep=TRUE, prob=FALSE,cellnumbers=FALSE, tryf=50, warn=2, lonlatCorrection=TRUE)))
names(pseudoabs_pts)<-paste0("X",setlist)
```

###  Prepare occurrence (presence-pseudoabsence) datasets for modelling

```{r create eu_presence_absence datasets}
# extract data from predictors for absences
pseudoabs_pts1<-lapply(pseudoabs_pts, function(x) raster::extract(rmiclimpreds,x))

# add absence indicator
add.occ<-function(x,y){
occ<-rep(y,nrow(x))
cbind(x,occ)
}

pseudoabs_pts2<-lapply(pseudoabs_pts1, function(x) add.occ(x,0))

# extract eu presences and add presence indicator 
presence<-as.data.frame(euocc1@coords)
names(presence)<- c("x","y")
presence1<-raster::extract(rmiclimpreds,presence)
occ<-rep(1,nrow(presence1))
presence1<-cbind(presence1,occ)

# join each pseudoabsence set with presences 
eu_presabs.pts<-lapply(pseudoabs_pts2, function(x) rbind(x,presence1))
eu_presabs.coord<-lapply(pseudoabs_pts, function(x) rbind(x,presence))
```


### Identify highly correlated climate predictors from training data

```{r identifyCorrelated_RMI_Preds}
# convert eu data to dataframe
eu_presabs.pts.df<-lapply(eu_presabs.pts,function(x) as.data.frame(x))

# find attributes that are highly corrected 
highlyCorrelated_climate <-lapply(names(eu_presabs.pts.df),function(x) findCorrelation(cor(eu_presabs.pts.df[[x]],use = 'complete.obs'), cutoff=0.7,exact=TRUE,names=TRUE))

highlyCorrelated_climate 
eupreds<-as.data.frame(highlyCorrelated_climate[1])
kable(eupreds) %>%
kable_styling(bootstrap_options = c("striped"))
```

### Reomve highly correlated climate predictors from training data
```{r removeCorrelated_RMI_Preds}
drop_climate<-highlyCorrelated_climate[[1]]
rmiclimpreds_uncor<-dropLayer(rmiclimpreds,drop_climate)
```

### Add habitat and anthropogenic predictors

```{r add_habitatPreds,echo=FALSE}
habitat<-list.files((here("./data/external/habitat/landcover")),pattern='tif',full.names = T)
habitat_stack<-stack(habitat)
fullstack<-stack(rmiclimpreds_uncor,habitat_stack) #combine uncorrelated climate variable selected earlier with habitat



# clip fullstack to belgium extent (if using another country, replace with country boundary shapefile)
country<-shapefile(here("./data/external/GIS/belgium_boundary.shp"))
fullstack_crop<-crop(fullstack,country)
fullstack_be<-mask(fullstack_crop,country)

occ.full.data <-lapply(eu_presabs.coord, function(x) raster::extract(fullstack,x))
```


### Identify highly correlated predictors from the habitat/anthropogenic/climate stack (full stack)
```{r identifyCorrelatedPreds_from_fullStack}

# find attributes that are highly correlated
highlyCorrelated_full <-lapply(names(occ.full.data),function(x) findCorrelation(cor(occ.full.data[[x]],use = 'complete.obs'), cutoff=0.7,exact=TRUE,names=TRUE))
highlyCorrelated_vec<-unlist(highlyCorrelated_full)
eupreds1<-as.data.frame(highlyCorrelated_vec)
kable(eupreds1) %>%
kable_styling(bootstrap_options = c("striped"))
```
### Remove highly correlated predictors from full stack 
```{r removeCorrelatedPreds_from_fullStack}
occ.full.data<-sapply(names(occ.full.data),function (x) occ.full.data[[x]][,!(colnames(occ.full.data[[x]]) %in% highlyCorrelated_vec)],simplify=FALSE)
```


###  Identify and remove near zero variance predictors
```{r removeLowVarPreds_from_fullStack}
# identify low variance predictors
nzv_preds<-lapply(names(occ.full.data),function(x) nearZeroVar(occ.full.data[[x]],names=TRUE))
nzv_preds
nzv_preds.vec<-unique(unlist(nzv_preds))
nzv_preds.vec
# remove near zero variance predictors. They don't contribute to the model.
occ.full.data<-sapply(names(occ.full.data),function (x) occ.full.data[[x]][,!(colnames(occ.full.data[[x]]) %in% nzv_preds.vec)],simplify=FALSE)
```

### Build models with climate and habitat data

```{r run_euModel,message=FALSE,warning=FALSE}

# prepare data for modeling

occ.full.data.df<-lapply(occ.full.data, function(x) as.data.frame(x))

occ.full.data.df<- sapply(names(occ.full.data.df), function (x) cbind(occ.full.data.df[[x]],occ=eu_presabs.pts.df[[x]]$occ, deparse.level=0),simplify=FALSE)



factorVars<-function(df,var){
df[,c(var)]<-as.factor(df[,c(var)])
levels(df[,c(var)])<-c("absent","present")
df[,c(var)]<-relevel(df[,c(var)], ref = "present")
return(df)
}


occ.full.data.factor<-sapply(names(occ.full.data.df), function (x) factorVars(occ.full.data.df[[x]], "occ"),simplify=FALSE)
occ.full.data.forCaret<-sapply(names(occ.full.data.factor), function (x) replace(occ.full.data.factor[[x]], is.na(occ.full.data.factor[[x]]),0),simplify=FALSE)



# uncomment 2nd control options for  LOOCV (leave one out cross validation, which is aka as "jacknife" ) which should be used when occurrences are smaller than n=10 for each predictor in the model)

#control<-trainControl(method="LOOCV",savePredictions="final", preProc=c("center","scale"),classProbs=TRUE)
control <- trainControl(method="cv",number=4,savePredictions="final", preProc=c("center","scale"),classProbs=TRUE)
mylist<-list(
  glm =caretModelSpec(method = "glm",maxit=100),
  gbm= caretModelSpec(method = "gbm"),
  rf = caretModelSpec(method = "rf", importance = TRUE),
  earth= caretModelSpec(method = "earth"))

# set.seed(167)
 eu_models<-sapply(names(occ.full.data.forCaret), function(x) model_train_habitat <- caretList(
   occ~temprang + maxtemp + annpvarrecip_eea + corine_perWetland, data= occ.full.data.forCaret[[x]],
   trControl=control,
    tuneList=mylist), simplify=FALSE)

```
### Display model evaluation statistics

```{r show_euModel_accuracy}
EU_ModelResults1<-sapply(names(eu_models), function(x) resamples(eu_models[[x]]),simplify=FALSE)
Results.summary<-sapply(names(EU_ModelResults1), function(x) summary(EU_ModelResults1[[x]]),simplify=FALSE)
Results.summary
```

```{r show_euModel_correlation}
Model.cor<-sapply(names(eu_models), function(x) modelCor(resamples(eu_models[[x]])),simplify=FALSE)
Model.cor
```

### Create ensemble model 

```{r run eu_ensemble}

set.seed(458)

#hideoutput<-capture.output(
set.seed(458)
lm_ens_hab<-sapply(names(eu_models), function (x) caretEnsemble(eu_models[[x]], trControl=trainControl(method="cv",                                                               number=10,savePredictions= "final",classProbs = TRUE)),simplify=FALSE)

```


#### PDF export function 

```{r export_toPDF,echo=FALSE}
exportPDF<-function(rst,taxonkey,taxonName,nameextension,is.diff="FALSE"){
  filename=file.path(pdfOutput,paste("be_",taxonkey, "_",nameextension,sep=""))
  pdf(file=filename,width=10,height=8,paper="a4r")
  par(bty="n")#to turn off box around plot
  ifelse(is.diff=="TRUE", brks<-seq(-1, 1, by=0.2), brks <- seq(0, 1, by=0.1)) 
  nb <- length(brks)-1 
  pal <- colorRampPalette(rev(brewer.pal(11, 'Spectral')))
  cols<-pal(nb)
  maintitle<-paste(taxonName,taxonkey,"_",nameextension, sep= " ")
  plot(rst, breaks=brks, col=cols,main=maintitle, lab.breaks=brks,axes=FALSE)
  dev.off() 
} 
```

#### PNG export function 
```{r export_toPNG,echo=FALSE}
exportPNG<-function(rst,taxonkey,taxonName,nameextension,is.diff="FALSE"){
  filename=file.path(pdfOutput,paste("be_",taxonkey, "_",nameextension,sep=""))
  png(file=filename)
  par(bty="n")#to turn off box around plot
  ifelse(is.diff=="TRUE", brks<-seq(-1, 1, by=0.25), brks <- seq(0, 1, by=0.1)) 
  nb <- length(brks)-1 
  pal <- colorRampPalette(rev(brewer.pal(11, 'Spectral')))
  cols<-pal(nb)
  maintitle<-paste(taxonName,taxonkey,"_",nameextension, sep= " ")
  plot(rst, breaks=brks, col=cols,main=maintitle, lab.breaks=brks,axes=FALSE)
  dev.off() 
} 
```

###  Use EU level ensemble models (each using a separate pseudoabsence draw) to predict at European level 

```{r ensModel_predictEU,results= "hide", cache=TRUE}
 ens_pred_hab_eu1<-sapply(names(lm_ens_hab), function(x) raster::predict(fullstack,lm_ens_hab[[x]],type="prob"),simplify=FALSE)
 
```
### Use EU level ensemble models to predict for Belgium only  

```{r ensModel_predictBE,results="hide"}

# creates  country level rasters using the European level models
ens_pred_hab_be<-sapply(names(lm_ens_hab), function(x) raster::predict(fullstack_be,lm_ens_hab[[x]],type="prob"),simplify=FALSE)

# assign proj to rasters
laea_grs80<-CRS("+proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000 +ellps=GRS80 +towgs84=0,0,0,-0,-0,-0,0 +units=m +no_defs ")
sapply(names(ens_pred_hab_be), function (x) crs(ens_pred_hab_be[[x]])<-laea_grs80)

# export rasters as GeoTiffs
#lapply(names(ens_pred_hab_be), function(x) writeRaster(ens_pred_hab_be[[x]], filename=file.path(rasterOutput,paste(x,"_",taxonkey,"_hist.tif",sep="")),  format="GTiff",overwrite=TRUE))
```
###  Evaluate the performance of each the EU level ensemble models based on results from CV
```{r findThreshold,echo=FALSE}
# 1.indentify threshold where sensitivity=specifity

# function to return threshold where sens=spec from caret results 
findThresh<-function(df){
  df[c("rowIndex","obs","present")]
  df<-df %>%
    mutate(observed= ifelse(obs == "present",1,0)) %>%
    select(rowIndex,observed,predicted=present)
  result<-PresenceAbsence::optimal.thresholds(df,opt.methods = 2)
  return(result)
}

thresholds<-sapply(names(lm_ens_hab), function(x) findThresh(lm_ens_hab[[x]]$ens_model$pred),simplify=FALSE)
```

# 2. Using thresholds identified for each model in the previous step, assess performance of each model
```{r accuracyMetrics,echo=FALSE}
# accuracy measures
accuracyStats<-function(df,y){
  df[c("rowIndex","obs","present")]
  df<-df %>%
    mutate(observed= ifelse(obs == "present",1,0)) %>%
    select(rowIndex,observed,predicted=present)
  result<-PresenceAbsence::presence.absence.accuracy(df,threshold = y,st.dev=FALSE)
  return(result)
}
thresholds.df<-sapply(names(thresholds), function(x) accuracyStats(lm_ens_hab[[x]]$ens_model$pred,thresholds[[x]]$predicted),simplify=FALSE)
thresholds.comb<-do.call(rbind,thresholds.df)
kable(thresholds.comb,digits=2)
```

### plot the best EU level ensemble model
```{r Plot_ensModel_eu}
# specify best model below
bestModel<-lm_ens_hab$X6


  brks <- seq(0, 1, by=0.1) 
  nb <- length(brks)-1 
  pal <- colorRampPalette(rev(brewer.pal(8, 'Spectral')))
   cols<-pal(nb)
  plot(ens_pred_hab_eu1$X6, breaks=brks, col=cols,lab.breaks=brks)# specify best model
  plot(euocc1,pch=21,cex=.8,col="white",add=TRUE)#plots species presences in 10 fold cv comment this line to hide
  
```

### Subset Belgium occurrences 
```{r subset_countryLevel_occurrences,echo=FALSE}

#occ.eu is in WGS84, convert to same projection as country level shapefile (which is the same proj used for model outputs)
occ.eu.proj  <- spTransform(occ.eu,crs(country))
occ.country <- occ.eu.proj[country,]
plot(country)
plot(occ.country,pch=21,bg="green",cex=1,add=TRUE)
```

### plot the best EU level ensemble model showing only Belgium
```{r Plot_ensModel_be}
brks <- seq(0, 1, by=0.1) 
  nb <- length(brks)-1 
  pal <- colorRampPalette(rev(brewer.pal(11, 'Spectral')))
  cols<-pal(nb)
  plot(ens_pred_hab_be$X6, breaks=brks, col=cols,lab.breaks=brks) # specify best model
  plot(occ.country,pch=21,cex=1,add=TRUE)
  
```



### Clip habitat raster stack to Belgium 
```{r create BE_habitatStack}
habitat_stack<-stack(habitat)
habitat_only_stack<-crop(habitat_stack,country)
habitat_only_stack_be<-crop(habitat_only_stack,country)
```

### Create individual RCP (2.6, 4.5, 8.5) climate raster stacks for Belgium

```{r create BE_RCP_stacks}
be26 <- list.files((here("./data/external/climate/byEEA_finalRCP/belgium_rcps/rcp26")),pattern='tif',full.names = T)
belgium_stack26 <- stack(be26)

be45 <- list.files((here("./data/external/climate/byEEA_finalRCP/belgium_rcps/rcp45")),pattern='tif',full.names = T)
belgium_stack45 <- stack(be45)

be85 <- list.files((here("./data/external/climate/byEEA_finalRCP/belgium_rcps/rcp85")),pattern='tif',full.names = T)
belgium_stack85 <- stack(be85)
```

### Combine habitat stacks with climate stacks for each RCP scenario

```{r combine habitat_RCP_stacks}
fullstack26<-stack(be26,habitat_only_stack_be)
fullstack45<-stack(be45,habitat_only_stack_be)
fullstack85<-stack(be85,habitat_only_stack_be)
```

### Create and export RCP risk maps for each RCP scenario

```{r create_RCP_risk_maps}
ens_pred_hist<-raster::predict(fullstack_be,bestModel,type="prob")
ens_pred_hab26<-raster::predict(fullstack26,bestModel,type="prob")
crs(ens_pred_hab26)<-laea_grs80
writeRaster(ens_pred_hab26, filename=file.path(rasterOutput,paste("be_",taxonkey, "_rcp26.tif",sep="")), format="GTiff",overwrite=TRUE) 
exportPDF(ens_pred_hab26,taxonkey,taxonName=taxonName,"rcp26.pdf")
ens_pred_hab45<-raster::predict(fullstack45,bestModel,type="prob")
crs(ens_pred_hab45)<-laea_grs80
writeRaster(ens_pred_hab45, filename=file.path(rasterOutput,paste("be_",taxonkey, "_rcp45.tif",sep="")), format="GTiff",overwrite=TRUE) 
exportPDF(ens_pred_hab45,taxonkey,taxonName=taxonName,"rcp45.pdf")
ens_pred_hab85<-raster::predict(fullstack85,bestModel,type="prob")
crs(ens_pred_hab85)<-laea_grs80
writeRaster(ens_pred_hab85, filename=file.path(rasterOutput,paste("be_",taxonkey, "_rcp85.tif",sep="")), format="GTiff",overwrite=TRUE) 
exportPDF(ens_pred_hab85,taxonkey,taxonName=taxonName,"rcp85.pdf")
```


### Create and export RCP risk maps for each RCP scenario
```{r plot_RCP_risk_maps}

par(mfrow=c(2,2), mar= c(2,3,0.8,0.8))
plot(ens_pred_hist,breaks=brks, col=cols,lab.breaks=brks)
plot(ens_pred_hab26,breaks=brks, col=cols,lab.breaks=brks)
plot(ens_pred_hab45,breaks=brks, col=cols,lab.breaks=brks)
plot(ens_pred_hab85,breaks=brks, col=cols,lab.breaks=brks)
```



### Create and export "difference maps": the difference between predicted risk by each RCP scenario and historical climate

```{r create_difference_maps,echo=FALSE}
hist26_diff_hab<-overlay(ens_pred_hab26, ens_pred_hist, fun=function(r1,r2){return(r1-r2)})
writeRaster(hist26_diff_hab,filename=file.path(rasterOutput,paste("be_",taxonkey, "_rcp26_diff.tif",sep="")) , format="GTiff",overwrite=TRUE) 
exportPDF(hist26_diff_hab,taxonkey,taxonName=taxonName,"rcp26_diff.pdf","TRUE")


hist45_diff_hab<-overlay(ens_pred_hab45, ens_pred_hist, fun=function(r1,r2){return(r1-r2)})
writeRaster(hist45_diff_hab,filename=file.path(rasterOutput,paste("be_",taxonkey, "_rcp45_diff.tif",sep="")), format="GTiff",overwrite=TRUE) 
exportPDF(hist45_diff_hab,taxonkey,taxonName=taxonName,"rcp45_diff.pdf","TRUE")


hist85_diff_hab<-overlay(ens_pred_hab85, ens_pred_hist, fun=function(r1,r2){return(r1-r2)})
writeRaster(hist85_diff_hab, filename=file.path(rasterOutput,paste("be_",taxonkey, "_rcp_85_diff.tif",sep="")), format="GTiff",overwrite=TRUE) 
exportPDF(hist85_diff_hab,taxonkey,taxonName=taxonName,"rcp85_diff.pdf","TRUE")

par(mfrow=c(2,2), mar= c(2,3,0.8,0.8))
plot(hist26_diff_hab)
plot(hist45_diff_hab)
plot(hist85_diff_hab)

```



### Check spatial autocorrelation of residuals to assess whether occurrence data should be thinned
#### derive residuals from best model
```{r deriveResiduals}
predEns1<-bestModel$ens_model$pred
obs.numeric<-ifelse(predEns1$obs == "absent",0,1)
```

#### standardize residuals

```{r standardize_residuals}
stdres<-function(obs.numeric, yhat){
  num<-obs.numeric-yhat
  denom<-sqrt(yhat*(1-yhat))
  return(num/denom)
}
hab.res<-stdres(obs.numeric,predEns1$present)

# specify corresponding model number from eu_presabs.coord datafile to join data with xy locations. If best model is "X1", join with eu_presabs.coord$X1


res.best.coords1<-cbind(coordinates(eu_presabs.coord$X1),occ.full.data.forCaret$X1)
removedNAs.coords<-na.omit(res.best.coords1)
res.best.coords<-cbind(removedNAs.coords,hab.res)
res.best.geo<-as.geodata(res.best.coords,coords.col=1:2,data.col = 3)
summary(res.best.geo) #note distance is in meters
```

### Check Morans I.

```{r residual_MoransI}
#If Moran's I is very low (<0.10), or not significant, do not need to thin occurrences.
library(ape)
res.best.df<-as.data.frame(res.best.coords)
occ.dists <- as.matrix(dist(cbind(res.best.df[1], res.best.df[2])))
occ.dists.inv <- 1/occ.dists
diag(occ.dists.inv) <- 0
Moran.I(res.best.df$hab.res,occ.dists.inv,scaled=TRUE,alternative="greater")
```

### Code for Mondrian conformal prediction functions

```{r conformalPredictionfunctions,echo=FALSE}
# functions needed for conformal prediction function


GetLength<-function(x,y){
length(x[which(x<= y)])
}




CPconf<-function(pA,pB,confidence){
  if(pA > confidence && pB< confidence){
    predClass<-"classA"
  }else if(pA < confidence && pB> confidence){
    predClass<-"classB"
  }else if(pA< confidence && pB< confidence){
    predClass<-"noClass"
  }else{
    predClass<-"bothClasses"
    
    return(predClass)
  }}


#function to calculate confidence of each prediction

get.confidence<-function(pvalA,pvalB){
  secondHighest<-ifelse(pvalA>pvalB,pvalB,pvalA)
  conf<-(1-secondHighest)
  return(conf)
}

forcedCp<-function(pvalA,pvalB){
  ifelse(pvalA>pvalB,"presence","absence")
}

extractVals<-function(predras){
  library(raster)
  vals <-  raster::values(predras)
  coord <-  raster::xyFromCell(predras,1:ncell(predras))
  raster_fitted <- cbind(coord,vals)
  raster_fitted.df<-as.data.frame(raster_fitted)
  raster_fitted.df1<-na.omit(raster_fitted.df)
  raster_fitted.df1$presence<-raster_fitted.df1$vals
  raster_fitted.df1$absence<- (1-raster_fitted.df1$presence)
  return(raster_fitted.df1)
}
```



```{r ClassConformalPrediction,echo=FALSE}
classConformalPrediction<-function(x,y){
ens_results<- get("x")
ens_calib<-ens_results$ens_model$pred
calibPresence<-ens_calib %>%
  filter(obs=='present')%>%
    select(present)
calibPresence<-unname(unlist(calibPresence[c("present")]))
calibAbsence<-ens_calib %>%
  filter(obs=='absent')%>%
    select(absent)
  calibAbsence<-unname(unlist(calibAbsence[c("absent")]))
predicted.values<-extractVals(y)


testPresence<-predicted.values$presence
testAbsence<-predicted.values$absence

#derive p.Values for class A
smallrA<-lapply(testPresence,function(x) GetLength(calibPresence,x))
smallrA_1<- unlist (smallrA)+1
nCalibSet<-length(calibPresence)+1
pvalA<-smallrA_1+1/nCalibSet

# derive p.Values for Class B
smallrB<-lapply(testAbsence,function(x) GetLength(calibAbsence,x))
smallrB_1<- unlist (smallrB)+1
nCalibSetB<-length(calibAbsence)
pvalB<-smallrB_1/nCalibSetB

 pvalsdf<-as.data.frame(cbind(pvalA,pvalB,0.20))
 #raster_cp_20<-mapply(CPconf,pvalsdf$pvalA,pvalsdf$pvalB,pvalsdf[3])
 #table(raster_cp_20)

pvalsdf$conf<-get.confidence(pvalsdf$pvalA,pvalsdf$pvalB)
pvalsdf_1<-cbind(pvalsdf,predicted.values)
}
```

### Quantify confidence of predicted values using class conformal prediction

```{r quantifyConfidence}

# quantify confidence for country level predictions based on historical climate and under RCP scenarios of climate change

set.seed(1609)
pvalsdf_hist<-classConformalPrediction(bestModel,ens_pred_hist)
set.seed(447)
pvalsdf_rcp26<-classConformalPrediction(bestModel,ens_pred_hab26)
set.seed(568)
pvalsdf_rcp45<-classConformalPrediction(bestModel,ens_pred_hab45)
set.seed(988)
pvalsdf_rcp85<-classConformalPrediction(bestModel,ens_pred_hab85)

# option to export confidence and pvals as csv 
# write.csv(pvalsdf_hist,file=paste(genOutput,"confidence_",taxonkey, "_hist.csv",sep=""))
```

### Create confidence maps

```{r createConfidenceMaps,fig.show="hold"}
brks <- seq(0, 1, by=0.1) 
  nb <- length(brks)-1 
  pal <- colorRampPalette(rev(brewer.pal(4, 'Spectral')))
  cols<-pal(nb)
  

confidenceMaps<-function(x,taxonkey,taxonName,maptype){
pvals_dataframe<-get("x")
data.xyz <- pvals_dataframe[c("x","y","conf")]
rst <- rasterFromXYZ(data.xyz)
crs(rst)<-CRS("+proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000 +ellps=GRS80 +units=m +no_defs") 
plot(rst,breaks=brks, col=cols,lab.breaks=brks)
writeRaster(rst, filename=file.path(rasterOutput,paste("be_",taxonkey, "_",maptype,".tif",sep="")), format="GTiff",overwrite=TRUE)
exportPDF(rst,taxonkey,taxonName=taxonName,nameextension= paste(maptype,".pdf",sep=""))
return(rst)
}

par(mfrow=c(2,2), mar= c(2,3,0.8,0.8))
hist.conf.map<-confidenceMaps(pvalsdf_hist,taxonkey,taxonName,maptype="hist_conf")
rcp26.conf.map<-confidenceMaps(pvalsdf_rcp26,taxonkey,taxonName,maptype="rcp26_conf")
rcp45.conf.map<-confidenceMaps(pvalsdf_rcp45,taxonkey,taxonName,maptype="rcp45_conf")
rcp85.conf.map<-confidenceMaps(pvalsdf_rcp85,taxonkey,taxonName,maptype="rcp85_conf")
```


### Mask areas of below a set confidence level  

```{r maskLowConfidence,fig.show="hold"}
# Cutoff for "high" confidence can be modified below. Cutoff should be a value between 0 and 1. Values that are less than the cutoff are shown in gray.
cutoff<-0.70

conf.brks <- seq(0,1, by=0.1) 
  nb <- length(conf.brks) 
  pal <- colorRampPalette(rev(brewer.pal(4, 'Spectral')))
  cols<-pal(nb)

par(mfrow=c(2,2), mar= c(2,3,0.9,0.8))
m1<-hist.conf.map < cutoff
hist_masked<-mask(ens_pred_hist,m1,maskvalue=TRUE)
plot(hist_masked,breaks=conf.brks, col=cols,lab.breaks=conf.brks)
plot(country,add=TRUE,border="dark gray")

m2<-rcp26.conf.map < cutoff
rcp26_masked<-mask(ens_pred_hab26,m2,maskvalue=TRUE)
plot(rcp26_masked,breaks=conf.brks, col=cols,lab.breaks=conf.brks)
plot(country,add=TRUE,border="dark gray")

m3<-rcp45.conf.map < cutoff
rcp45_masked<-mask(ens_pred_hab45,m3,maskvalue=TRUE)
plot(rcp45_masked,breaks=conf.brks, col=cols,lab.breaks=conf.brks)
plot(country,add=TRUE,border="dark gray")

m4<-rcp85.conf.map < cutoff
rcp85_masked<-mask(ens_pred_hab85,m4,maskvalue=TRUE)
plot(rcp85_masked,breaks=conf.brks, col=cols,lab.breaks=conf.brks)
plot(country,add=TRUE,border="dark gray")
```
### confidence map of best model at EU level
```{r EUconfidence, fig.show="hold"}
brks <- seq(0, 1, by=0.1) 
  nb <- length(brks)-1 
  pal <- colorRampPalette(rev(brewer.pal(4, 'Spectral')))
set.seed(792)  
pvalsdf_hist_eu<-classConformalPrediction(bestModel,ens_pred_hab_eu1$X6)
hist.conf.map.eu<-confidenceMaps(pvalsdf_hist_eu,taxonkey,taxonName,maptype="hist_conf_eu")
```
  
### Get variable importance of best european model

```{r get_var_importance_eu,echo=TRUE}
variableImportance<-varImp(bestModel)
kable(variableImportance,digits=2,caption="Variable Importance") %>%
kable_styling(bootstrap_options = c("striped"))
write.csv(variableImportance,file = paste0(genOutput,taxonkey,"_varImp_EU_model.csv"))
```

### Generate and export response curves in order of variable importance

```{r responseCurves}
topPreds <- variableImportance[with(variableImportance,order(-overall)),]
varNames<-rownames(topPreds)
## combine predictions from each model for each variable
## train data needs to be the training data used in the individual models used to build the ensemble model. This info can be extracted from the best ensemble model (ie. bestModel)
bestModel.train<-bestModel$models[[1]]$trainingData

partial_gbm<-function(x){
  m.gbm<-pdp::partial(bestModel$models$gbm$finalModel,pred.var=paste(x),train = bestModel.train,type="classification",
                      prob=TRUE,n.trees= bestModel$models$gbm$finalModel$n.trees, which.class = 1,grid.resolution=nrow(bestModel.train))
}



gbm.partial.list<-lapply(varNames,partial_gbm)

partial_glm<-function(x){
m.glm<-pdp::partial(bestModel$models$glm$finalModel,pred.var=paste(x),train = bestModel.train,type="classification",
              prob=TRUE,which.class = 1,grid.resolution=nrow(bestModel.train))
}

glm.partial.list<-lapply(varNames,partial_glm)

partial_rf<-function(x){
  pdp::partial(bestModel$models$rf$finalModel,pred.var=paste(x),train = bestModel.train,type="classification",
              prob=TRUE,which.class = 1,grid.resolution=nrow(bestModel.train))
}

rf.partial.list<-lapply(varNames,partial_rf)


partial_mars<-function(x){
m.mars<-pdp::partial(bestModel$models$earth$finalModel,pred.var=paste(x),train = bestModel.train,type="classification",
              prob=TRUE,which.class = 2,grid.resolution=nrow(bestModel.train)) # class=2 because in earth pkg, absense is the first class
}

mars.partial.list<-lapply(varNames,partial_mars)


names(glm.partial.list)<-varNames
names(gbm.partial.list)<-varNames
names(rf.partial.list)<-varNames
names(mars.partial.list)<-varNames

glm.partial.df<-as.data.frame(glm.partial.list)
gbm.partial.df<-as.data.frame(gbm.partial.list)
rf.partial.df<-as.data.frame(rf.partial.list)
mars.partial.df<-as.data.frame(mars.partial.list)

predx<-data.frame()
predy<-data.frame()

for (i in varNames){
  predx <- rbind(predx, as.data.frame(paste(i,i,sep=".")))
  predy<- rbind(predy,as.data.frame(paste(i,"yhat",sep=".")))
}
names(predx)<-""
names(predy)<-""

predx1<-t(predx)
predy1<-t(predy)


glm.partial.df$data<-'GLM'
gbm.partial.df$data<-'GBM'
rf.partial.df$data<-'RF'
mars.partial.df$data<-'MARS'

all_dfs<-rbind.data.frame(glm.partial.df,gbm.partial.df,rf.partial.df,mars.partial.df)


responseCurves<-function(x,y) {
  colors <- c("GLM" = "gray", "GBM"="red","RF"="blueviolet","MARS"= "hotpink") 
  ggplot(all_dfs,(aes(x=.data[[x]],y=.data[[y]]))) +
    geom_line(aes(color = data), size =1.2, position=position_dodge(width=0.2))+
   theme_bw()+
    labs(y="Partial probability", x= gsub("//..*","",x),color="Legend") +
    scale_color_manual(values = colors)
}  

allplots<-map2(predx1,predy1, ~responseCurves(.x,.y))

#export plots as PNGs
for(i in seq_along(allplots)){
  png(paste0(genOutput,taxonkey,"_",i,".png"),width = 5, height = 5, units = "in",res=300)
  print(allplots[[i]])
  dev.off()
}
```


### Plot response curves
```{r plotResponseCurves,fig.show="hold"}

par(mfrow=c(3,4))
for(i in seq_along(allplots)){
  print(allplots[[i]])
}
```

###  Evaluate the performance of each the EU level ensemble models using independent data set from the future 
#####################################################################

```{r prepareTestData}
# read in and prepare independent data
#2011-2021
eval.data<-read.csv("C:/Users/amyjs/Documents/projects/xps15/xps15/wiSDM/data/external/0001753-230828120925497/0001753-230828120925497.csv",header=TRUE,sep ="\t",quote="")

#enter value for max coordinate uncertainty in meters.

eval.data.occ<-eval.data %>%
  filter(is.na(coordinateUncertaintyInMeters)| coordinateUncertaintyInMeters< 1000) 

eval.data.occ$lon_dplaces<-sapply(na.omit(eval.data.occ$decimalLongitude), function(x) decimalplaces(x))
eval.data.occ$lat_dplaces<-sapply(eval.data.occ$decimalLatitude, function(x) decimalplaces(x))
eval.data.occ[eval.data.occ$lon_dplaces < 4& eval.data.occ$lat_dplaces < 4 , ]<-NA
eval.data.occ<-eval.data.occ[ which(!is.na(eval.data.occ$lon_dplaces)),]
eval.data.occ<-within(eval.data.occ,rm("lon_dplaces","lat_dplaces"))

eval.data.occ<-eval.data.occ[c("decimalLongitude", "decimalLatitude")]
coordinates(eval.data.occ)<- c("decimalLongitude", "decimalLatitude")
proj4string(eval.data.occ)<-CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0")#specify here the existing coord.sys of the data
eval.data.occ.proj<-spTransform(eval.data.occ,rmiproj)
```
########################################################################
```{r evaulateEuModelsTestData,echo=FALSE}
#Convert predicted probabilities of EU level risk maps into binary risk maps (present/absence) using thresholds from earlier step

# Eu level
binary_eu_rasters<-sapply(names(thresholds), function(x) raster::reclassify(ens_pred_hab_eu1[[x]],c(0,thresholds[[x]]$predicted,0, thresholds[[x]]$predicted,1,1)),simplify=FALSE)




eu_eval<-function (ras,y){
indep.bil<-raster::extract(ras,y,method="bilinear")
indep.bil.df<-as.data.frame(indep.bil)
indep.bil.df<-indep.bil.df %>%
  mutate(predicted= ifelse(indep.bil >= 0.5,"present","absent")) 
indep.bil.df$observed<-rep("present",nrow(indep.bil.df))
indep.bil.df$predicted<-as.factor(indep.bil.df$predicted)
indep.bil.df$observed<-as.factor(indep.bil.df$observed)
xtab<-table(indep.bil.df$predicted,indep.bil.df$observed)
return(xtab)
}


testeval.eu.bin.rast<-sapply(names(binary_eu_rasters), function(x) eu_eval(binary_eu_rasters[[x]],eval.data.occ.proj),simplify=FALSE)
testeval.eu.bin.rast

```
```{r evaulateCountryModelsTestData,echo=FALSE}
binary_be_rasters<-sapply(names(thresholds), function(x) raster::reclassify(ens_pred_hab_be[[x]],c(0,thresholds[[x]]$predicted,0, thresholds[[x]]$predicted,1,1)),simplify=FALSE)
testeval.be.bin.rast<-sapply(names(binary_eu_rasters), function(x) eu_eval(binary_be_rasters[[x]],eval.data.occ.proj),simplify=FALSE)
testeval.be.bin.rast
```

